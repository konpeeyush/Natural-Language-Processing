{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35b0b785",
   "metadata": {},
   "source": [
    "1. Consider an example to find the similarity between two vectors – ‘x’ and ‘y’, using Cosine Similarity.\n",
    "- The ‘x’ vector has values, x = { 3, 2, 0, 5 }\n",
    "- The ‘y’ vector has values, y = { 1, 0, 0, 0 }\n",
    "- Design a program to compute the similarity between x and y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2c9d9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: [3 2 0 5]\n",
      "B: [1 0 0 0]\n",
      "Cosine Similarity: 0.48666426339228763\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    " \n",
    "# define two lists or array\n",
    "A = np.array([3,2,0,5])\n",
    "B = np.array([1,0,0,0])\n",
    " \n",
    "print(\"A:\", A)\n",
    "print(\"B:\", B)\n",
    " \n",
    "# compute cosine similarity\n",
    "cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "print(\"Cosine Similarity:\", cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e305b3",
   "metadata": {},
   "source": [
    "2. Consider two sets A = (0,1,2,5,6) and B = (0, 2,3, 5, 7,9).\n",
    "- How similar are A and B?\n",
    "- Design a program to compute the similarity using Jaccard similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc4ef3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between A and B is 0.375\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def jaccard_set(list1, list2):\n",
    "    \"\"\"Define Jaccard Similarity function for two sets\"\"\"\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(list1) + len(list2)) - intersection\n",
    "    return float(intersection) / union\n",
    "\n",
    "# Define some binary vectors\n",
    "A=[0,1,2,5,6]\n",
    "B=[0,2,3,5,7,9]\n",
    "\n",
    "# Find similarity among the vectors\n",
    "simAB=jaccard_set(A,B)\n",
    "print(\"Similarity between A and B is\", simAB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7505094",
   "metadata": {},
   "source": [
    "3. Consider Three documents:\n",
    "- d1:“Jack London traveled to Oakland”\n",
    "- d2: “Jack London traveled to the city of Oakland” \n",
    "- d3: “Jack traveled from Oakland to London”\n",
    "- **Based on shingles of size 2 (2-grams or bigrams), what are the Jaccard coefficients J(d1, d2) and J(d1, d3)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "405fd9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between d1 and d2 is : 0.375\n",
      "Similarity between d1 and d3 is : 0.0\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import nltk.corpus\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import bigrams, trigrams, ngrams\n",
    "\n",
    "d1= 'Jack London traveled to Oakland'\n",
    "d2= 'Jack London traveled to the city of Oakland'\n",
    "d3= 'Jack traveled from Oakland to London'\n",
    "#Tokenizing the Strings\n",
    "d1_tokens = word_tokenize(d1)\n",
    "d2_tokens = word_tokenize(d2)\n",
    "d3_tokens = word_tokenize(d3)\n",
    "# Making shingles\n",
    "d1_shingle = list(nltk.ngrams(d1_tokens,2))\n",
    "d2_shingle = list(nltk.ngrams(d2_tokens,2))\n",
    "d3_shingle = list(nltk.ngrams(d3_tokens,2))\n",
    "# Jaccard Similarity Formula\n",
    "def jaccard_set(list1, list2):\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(list1) + len(list2)) - intersection\n",
    "    return float(intersection) / union\n",
    "\n",
    "print(\"Similarity between d1 and d2 is :\", jaccard_set(d1_shingle, d2_shingle))\n",
    "print(\"Similarity between d1 and d3 is :\", jaccard_set(d1_shingle, d3_shingle))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdfe473",
   "metadata": {},
   "source": [
    "4. Consider set of documents as \n",
    "- D1 : I am Sam.\n",
    "- D2 : Sam I am.\n",
    "- D3 : I do not like green eggs and ham.\n",
    "- D4 : I do not like them, Sam I am.\n",
    "    - **Design a program for  (k = 1)-shingles of D1 U D2 U D3 U D4 : U is UNION**\n",
    "    - **Design a program for  (k = 2)-shingles of D1 U D2 U D3 U D4 : U is UNION**\n",
    "    - **Design a program for  (k = 3)-Character shingles of D1 U D2**\n",
    "    - **Design a program for  (k = 4)-Character shingles of D1 U D2**   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "abb4264d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k= 1 shingles \n",
      " [('I',), ('am',), ('Sam',), ('.',), ('Sam',), ('I',), ('am',), ('.',), ('I',), ('do',), ('not',), ('like',), ('green',), ('eggs',), ('and',), ('ham',), ('.',), ('I',), ('do',), ('not',), ('like',), ('them',), (',',), ('Sam',), ('I',), ('am',), ('.',)]\n",
      "\n",
      "\n",
      "For k= 2 shingles \n",
      " [('I', 'am'), ('am', 'Sam'), ('Sam', '.'), ('Sam', 'I'), ('I', 'am'), ('am', '.'), ('I', 'do'), ('do', 'not'), ('not', 'like'), ('like', 'green'), ('green', 'eggs'), ('eggs', 'and'), ('and', 'ham'), ('ham', '.'), ('I', 'do'), ('do', 'not'), ('not', 'like'), ('like', 'them'), ('them', ','), (',', 'Sam'), ('Sam', 'I'), ('I', 'am'), ('am', '.')]\n",
      "\n",
      "\n",
      "For k=3 character Shingle \n",
      " [('I', ' ', 'a'), (' ', 'a', 'm'), ('a', 'm', ' '), ('m', ' ', 'S'), (' ', 'S', 'a'), ('S', 'a', 'm'), ('a', 'm', '.'), ('S', 'a', 'm'), ('a', 'm', ' '), ('m', ' ', 'I'), (' ', 'I', ' '), ('I', ' ', 'a'), (' ', 'a', 'm'), ('a', 'm', '.')]\n",
      "\n",
      "\n",
      "For k=4 character Shingle \n",
      " [('I', ' ', 'd'), (' ', 'd', 'o'), ('d', 'o', ' '), ('o', ' ', 'n'), (' ', 'n', 'o'), ('n', 'o', 't'), ('o', 't', ' '), ('t', ' ', 'l'), (' ', 'l', 'i'), ('l', 'i', 'k'), ('i', 'k', 'e'), ('k', 'e', ' '), ('e', ' ', 'g'), (' ', 'g', 'r'), ('g', 'r', 'e'), ('r', 'e', 'e'), ('e', 'e', 'n'), ('e', 'n', ' '), ('n', ' ', 'e'), (' ', 'e', 'g'), ('e', 'g', 'g'), ('g', 'g', 's'), ('g', 's', ' '), ('s', ' ', 'a'), (' ', 'a', 'n'), ('a', 'n', 'd'), ('n', 'd', ' '), ('d', ' ', 'h'), (' ', 'h', 'a'), ('h', 'a', 'm'), ('a', 'm', '.'), ('I', ' ', 'd'), (' ', 'd', 'o'), ('d', 'o', ' '), ('o', ' ', 'n'), (' ', 'n', 'o'), ('n', 'o', 't'), ('o', 't', ' '), ('t', ' ', 'l'), (' ', 'l', 'i'), ('l', 'i', 'k'), ('i', 'k', 'e'), ('k', 'e', ' '), ('e', ' ', 't'), (' ', 't', 'h'), ('t', 'h', 'e'), ('h', 'e', 'm'), ('e', 'm', ','), ('m', ',', ' '), (',', ' ', 'S'), (' ', 'S', 'a'), ('S', 'a', 'm'), ('a', 'm', ' '), ('m', ' ', 'I'), (' ', 'I', ' '), ('I', ' ', 'a'), (' ', 'a', 'm'), ('a', 'm', '.')]\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import nltk.corpus\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "d1 = \"I am Sam.\"\n",
    "d2 = \"Sam I am.\"\n",
    "d3 = \"I do not like green eggs and ham.\"\n",
    "d4 = \"I do not like them, Sam I am.\"\n",
    "#Tokenizing the Strings\n",
    "d1_tokens = word_tokenize(d1)\n",
    "d2_tokens = word_tokenize(d2)\n",
    "d3_tokens = word_tokenize(d3)\n",
    "d4_tokens = word_tokenize(d4)\n",
    "# Making shingles for k=1 and k=2\n",
    "for i in range(2):\n",
    "    d1_shingle1 = list(nltk.ngrams(d1_tokens,i+1))\n",
    "    d2_shingle1 = list(nltk.ngrams(d2_tokens,i+1))\n",
    "    d3_shingle1 = list(nltk.ngrams(d3_tokens,i+1))\n",
    "    d4_shingle1 = list(nltk.ngrams(d4_tokens,i+1))\n",
    "    print(\"For k=\",i+1,\"shingles \\n\",d1_shingle1+d2_shingle1+d3_shingle1+d4_shingle1)\n",
    "    print(\"\\n\")\n",
    "# Character shingles k=3 and k=4\n",
    "for i in range(2):\n",
    "    d1_shingle2=list(nltk.ngrams(d1,i+2))\n",
    "    d2_shingle2=list(nltk.ngrams(d2,i+2))\n",
    "    d3_shingle2=list(nltk.ngrams(d3,i+2))\n",
    "    d4_shingle2=list(nltk.ngrams(d4,i+2))\n",
    "print(\"For k=3 character Shingle \\n\",d1_shingle2+d2_shingle2)\n",
    "print(\"\\n\")\n",
    "print(\"For k=4 character Shingle \\n\",d3_shingle2+d4_shingle2)\n",
    "# We can exclude all the whitespaces by using string.replace(\" \",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37528475",
   "metadata": {},
   "source": [
    "5. Suppose our document D is the string abcdabd, and we pick k = 2. Then the set of 2-shingles for D is {ab, bc, cd, da, bd}. Note that the substring ab appears twice within D, but appears only once as a shingle. A variation of shingling produces a bag, rather than a set, so each shingle would appear in the result as many times as it appears in the document. Design a program to model the above scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "67a5ff40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 'b'), ('b', 'c'), ('c', 'd'), ('d', 'a'), ('a', 'b'), ('b', 'd')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "d=\"abcdabd\"\n",
    "ans=list(nltk.ngrams(d,2)) \n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48594765",
   "metadata": {},
   "source": [
    "7. Consider this sentence: “a rose is a rose is a rose”.  And represent this document as set of shingles (Word n gram).\n",
    "\n",
    "- **Design a program for extracting shingles  for n = 3 and n=4  for above sentence.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76a9afa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For shingles k= 3 \n",
      " [('a',), ('rose',), ('is',), ('a',), ('rose',), ('is',), ('a',), ('rose',)]\n",
      "\n",
      "\n",
      "For shingles k= 4 \n",
      " [('a', 'rose'), ('rose', 'is'), ('is', 'a'), ('a', 'rose'), ('rose', 'is'), ('is', 'a'), ('a', 'rose')]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import bigrams, trigrams, ngrams\n",
    "d = \"a rose is a rose is a rose\"\n",
    "d_token=word_tokenize(d)\n",
    "# Making shingles for k=3 and k=4\n",
    "for i in range(2):\n",
    "    d_shingle = list(nltk.ngrams(d_token,i+1))\n",
    "    print(\"For shingles k=\",i+3,\"\\n\",d_shingle)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5caa7d",
   "metadata": {},
   "source": [
    "8. Compute the similarity between:\n",
    "- **night and nacht**\n",
    "- **Ashish and Aasheesh**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a89a5e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between night and nacht is : 0.14285714285714285\n",
      "Similarity between Ashish and Aasheesh is : 0.09090909090909091\n",
      "[('n', 'a'), ('a', 'c'), ('c', 'h'), ('h', 't')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import bigrams, trigrams, ngrams\n",
    "d1=\"night\"\n",
    "d2=\"nacht\"\n",
    "d3=\"Ashish\"\n",
    "d4=\"Aasheesh\"\n",
    "token1=list(nltk.ngrams(d1,2))\n",
    "token2=list(nltk.ngrams(d2,2))\n",
    "token3=list(nltk.ngrams(d3,2))\n",
    "token4=list(nltk.ngrams(d4,2))\n",
    "def jaccard_set(list1, list2):\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(list1) + len(list2)) - intersection\n",
    "    return float(intersection) / union\n",
    "\n",
    "print(\"Similarity between night and nacht is :\", jaccard_set(token1, token2))\n",
    "print(\"Similarity between Ashish and Aasheesh is :\", jaccard_set(token3, token4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e292b09a",
   "metadata": {},
   "source": [
    "9. Consider a case insensitive query and document collection with a query Q and a document collection consisting of the following three documents: \n",
    "- **Q: \"gold silver truck\"**\n",
    "    - D1: \"Shipment of gold damaged in a fire\"\n",
    "    - D2: \"Delivery of silver arrived in a silver truck\" \n",
    "    - D3: \"Shipment of gold arrived in a truck\"\n",
    "**Design a program to compute the similarity between**\n",
    "- Q & D1\n",
    "- Q & D2\n",
    "- Q & D3\n",
    "- **Find which document (D) matches best with the query (Q)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb41a584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between D1 and Q is : 0.0\n",
      "Similarity between D2 and Q is : 0.125\n",
      "Similarity between D3 and Q is : 0.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.util import bigrams, trigrams, ngrams\n",
    "Q=\"gold silver truck\"\n",
    "d1=\"Shipment of gold damaged in a fire\"\n",
    "d2=\"Delivery of silver arrived in a silver truck\"\n",
    "d3=\"Shipment of gold arrived in a truck\"\n",
    "#Tokenizing the Strings\n",
    "d1_tokens = word_tokenize(d1)\n",
    "d2_tokens = word_tokenize(d2)\n",
    "d3_tokens = word_tokenize(d3)\n",
    "Q_tokens = word_tokenize(Q)\n",
    "# Making shingles\n",
    "d1_shingle = list(nltk.ngrams(d1_tokens,2))\n",
    "d2_shingle = list(nltk.ngrams(d2_tokens,2))\n",
    "d3_shingle = list(nltk.ngrams(d3_tokens,2))\n",
    "Q_shingle = list(nltk.ngrams(Q_tokens,2))\n",
    "# Jaccard Similarity Formula\n",
    "def jaccard_set(list1, list2):\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(list1) + len(list2)) - intersection\n",
    "    return float(intersection) / union\n",
    "\n",
    "print(\"Similarity between D1 and Q is :\", jaccard_set(d1_shingle, Q_shingle))\n",
    "print(\"Similarity between D2 and Q is :\", jaccard_set(d2_shingle, Q_shingle))\n",
    "print(\"Similarity between D3 and Q is :\", jaccard_set(d_shingle, Q_shingle))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
